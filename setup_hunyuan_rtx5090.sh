#!/bin/bash
set -e

# Colors for better output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
NC='\033[0m' # No Color

log() {
    echo -e "${GREEN}[$(date +'%Y-%m-%d %H:%M:%S')] $1${NC}"
}

warn() {
    echo -e "${YELLOW}[WARNING] $1${NC}"
}

error() {
    echo -e "${RED}[ERROR] $1${NC}"
    exit 1
}

info() {
    echo -e "${BLUE}[INFO] $1${NC}"
}

success() {
    echo -e "${PURPLE}[SUCCESS] $1${NC}"
}

# Detect Ubuntu version and set appropriate packages
detect_ubuntu_version() {
    if [ -f /etc/os-release ]; then
        . /etc/os-release
        UBUNTU_VERSION=$VERSION_ID
        log "Detected Ubuntu version: $UBUNTU_VERSION"
        
        # Set OpenGL packages based on Ubuntu version
        if [[ "$UBUNTU_VERSION" == "24.04" ]] || [[ "$UBUNTU_VERSION" > "22.04" ]]; then
            OPENGL_PACKAGES="libopengl0 libglx0 libgl1-mesa-dri mesa-utils"
            GLIB_PACKAGE="libglib2.0-0t64"
        else
            OPENGL_PACKAGES="libgl1-mesa-glx"
            GLIB_PACKAGE="libglib2.0-0"
        fi
    else
        warn "Could not detect Ubuntu version, using default packages"
        OPENGL_PACKAGES="libopengl0 libglx0 libgl1-mesa-dri mesa-utils"
        GLIB_PACKAGE="libglib2.0-0t64"
    fi
}

# Check vast.ai environment and RTX 5090
check_vastai_environment() {
    log "ðŸŒ Checking vast.ai environment..."
    
    # Check if running in vast.ai
    if [ -f "/etc/vastai_instance_info" ] || [ -n "$VAST_CONTAINERLABEL" ]; then
        success "âœ… Running on vast.ai instance"
    else
        info "Running on server (not vast.ai detected)"
    fi
    
    # Check GPU
    if command -v nvidia-smi &> /dev/null; then
        GPU_INFO=$(nvidia-smi --query-gpu=name --format=csv,noheader,nounits)
        VRAM_INFO=$(nvidia-smi --query-gpu=memory.total --format=csv,noheader,nounits)
        CUDA_VERSION=$(nvidia-smi --query-gpu=driver_version --format=csv,noheader,nounits)
        
        log "ðŸŽ® Detected GPU: $GPU_INFO"
        log "ðŸ’¾ VRAM: ${VRAM_INFO} MB"
        log "ðŸ”§ CUDA Driver: $CUDA_VERSION"
        
        if [[ "$GPU_INFO" == *"5090"* ]]; then
            success "ðŸš€ RTX 5090 detected - perfect for HunyuanVideo I2V!"
            
            # Check compute capability
            COMPUTE_CAP=$(nvidia-smi --query-gpu=compute_cap --format=csv,noheader,nounits 2>/dev/null || echo "9.0")
            if [[ "$COMPUTE_CAP" == "9.0" ]]; then
                success "âœ… Blackwell architecture (sm_90) confirmed"
            fi
        else
            warn "âš ï¸  GPU is not RTX 5090. Performance may vary."
        fi
        
        # Check VRAM (RTX 5090 should have ~32GB)
        VRAM_GB=$((VRAM_INFO / 1024))
        if [ $VRAM_GB -ge 24 ]; then
            success "âœ… Sufficient VRAM: ${VRAM_GB}GB"
        else
            warn "âš ï¸  Low VRAM detected: ${VRAM_GB}GB"
        fi
    else
        error "âŒ nvidia-smi not found. Please ensure NVIDIA drivers are installed."
    fi
}

log "ðŸš€ HunyuanVideo Image-to-Video Setup for RTX 5090 on Vast.ai"
echo -e "${BLUE}================================================================${NC}"
echo -e "${GREEN}Setting up HunyuanVideo I2V with RTX 5090 optimizations${NC}"
echo -e "${BLUE}================================================================${NC}"

# --------- STEP 0: Environment Check ----------
check_vastai_environment

# --------- STEP 1: Detect Ubuntu Version and Fix Dependencies ----------
detect_ubuntu_version

log "ðŸ“¦ Installing system dependencies for Ubuntu $UBUNTU_VERSION..."
export DEBIAN_FRONTEND=noninteractive

# Update package lists
apt update

# Install packages with Ubuntu version-specific handling
log "Installing OpenGL packages: $OPENGL_PACKAGES"
log "Installing GLib package: $GLIB_PACKAGE"

apt install -y \
    python3 \
    python3-pip \
    python3-venv \
    python3-dev \
    git \
    wget \
    curl \
    ffmpeg \
    build-essential \
    cmake \
    $OPENGL_PACKAGES \
    $GLIB_PACKAGE \
    libsm6 \
    libxext6 \
    libxrender-dev \
    libgomp1 \
    libfontconfig1 \
    unzip \
    htop \
    tree \
    ca-certificates \
    gnupg \
    lsb-release

success "âœ… System dependencies installed successfully"

# --------- STEP 2: Setup Workspace ----------
log "ðŸ“ Setting up workspace..."
WORKSPACE_DIR="/workspace"
if [ ! -d "$WORKSPACE_DIR" ]; then
    WORKSPACE_DIR="$HOME"
    warn "Using $WORKSPACE_DIR as workspace directory"
fi

cd "$WORKSPACE_DIR"
log "Working directory: $(pwd)"

# --------- STEP 3: Clone HunyuanVideo Repository ----------
log "ðŸ“¥ Cloning HunyuanVideo repository..."
if [ ! -d "HunyuanVideo" ]; then
    git clone https://github.com/Tencent-Hunyuan/HunyuanVideo.git
    success "âœ… Repository cloned"
else
    log "Repository exists, pulling latest changes..."
    cd HunyuanVideo
    git pull origin main || git pull origin master
    cd "$WORKSPACE_DIR"
fi

cd HunyuanVideo

# --------- STEP 4: Python Environment Setup ----------
log "ðŸ Setting up Python environment for RTX 5090..."
if [ ! -d "hunyuan_i2v_env" ]; then
    python3 -m venv hunyuan_i2v_env
    success "âœ… Virtual environment created"
fi

source hunyuan_i2v_env/bin/activate
log "Python environment activated"

# Verify Python version
PYTHON_VERSION=$(python --version | cut -d' ' -f2)
log "Using Python version: $PYTHON_VERSION"

# --------- STEP 5: CRITICAL - RTX 5090 PyTorch Installation ----------
log "ðŸ”§ Installing RTX 5090 optimized PyTorch with CUDA 12.8..."
pip install --upgrade pip setuptools wheel

# Install PyTorch with CUDA 12.8 for RTX 5090
log "Installing PyTorch for Blackwell architecture..."
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128

# Verify PyTorch installation
log "ðŸ§ª Verifying PyTorch installation..."
python -c "
import torch
print(f'âœ… PyTorch version: {torch.__version__}')
print(f'âœ… CUDA available: {torch.cuda.is_available()}')
print(f'âœ… CUDA version: {torch.version.cuda}')
if torch.cuda.is_available():
    print(f'âœ… GPU: {torch.cuda.get_device_name(0)}')
    print(f'âœ… VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB')
    major, minor = torch.cuda.get_device_capability(0)
    print(f'âœ… Compute Capability: sm_{major}{minor}')
else:
    print('âŒ CUDA not available!')
    exit(1)
"

if [ $? -ne 0 ]; then
    error "âŒ PyTorch installation failed or CUDA not available"
fi

success "âœ… PyTorch with CUDA 12.8 installed successfully"

# Install RTX 5090 optimized packages
log "Installing RTX 5090 optimized packages..."
pip install ninja

# Try to install flash-attention (may fail on some systems, that's okay)
log "Attempting to install Flash Attention..."
if pip install flash-attn --no-build-isolation; then
    success "âœ… Flash Attention installed"
else
    warn "âš ï¸ Flash Attention installation failed, will use alternatives"
fi

# --------- STEP 6: RTX 5090 Environment Variables ----------
log "âš™ï¸ Setting RTX 5090 environment variables..."
cat >> ~/.bashrc << 'EOF'
# RTX 5090 Optimizations
export CUDA_VISIBLE_DEVICES=0
export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512,garbage_collection_threshold:0.8
export TORCH_CUDA_ARCH_LIST="9.0"
export CUDA_LAUNCH_BLOCKING=0
export PYTORCH_NVFUSER_DISABLE_FALLBACK=1
EOF

# Apply environment variables for current session
export CUDA_VISIBLE_DEVICES=0
export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512,garbage_collection_threshold:0.8
export TORCH_CUDA_ARCH_LIST="9.0"
export CUDA_LAUNCH_BLOCKING=0

# --------- STEP 7: Install Dependencies ----------
log "ðŸ“¦ Installing project dependencies..."

# Install essential packages first
pip install diffusers transformers accelerate safetensors opencv-python pillow imageio imageio-ffmpeg

if [ -f "requirements.txt" ]; then
    log "Found requirements.txt, processing..."
    cp requirements.txt requirements.txt.backup
    
    # Remove conflicting versions for RTX 5090 compatibility
    sed -i '/torch==/d' requirements.txt
    sed -i '/torchvision==/d' requirements.txt
    sed -i '/torchaudio==/d' requirements.txt
    sed -i '/numpy==/d' requirements.txt
    sed -i '/pandas==/d' requirements.txt
    
    # Install compatible versions
    pip install "numpy>=1.26,<2.0"
    pip install "pandas>=2.0,<3.0"
    
    # Install remaining dependencies
    pip install -r requirements.txt
    success "âœ… Dependencies installed from requirements.txt"
else
    warn "requirements.txt not found, installed essential packages"
fi

# --------- STEP 8: HuggingFace Authentication ----------
log "ðŸ”‘ Setting up HuggingFace authentication..."
if [ -z "$HF_TOKEN" ]; then
    echo ""
    echo -e "${YELLOW}âš ï¸  HuggingFace token required for model downloads!${NC}"
    echo -e "${BLUE}Please get your token from: https://huggingface.co/settings/tokens${NC}"
    echo -e "${GREEN}Then run: export HF_TOKEN='your_token_here'${NC}"
    echo ""
    read -p "Enter your HuggingFace token: " HF_TOKEN
    export HF_TOKEN="$HF_TOKEN"
fi

if [ -n "$HF_TOKEN" ]; then
    pip install huggingface_hub
    huggingface-cli login --token "$HF_TOKEN"
    success "âœ… HuggingFace authentication configured"
else
    error "âŒ HuggingFace token is required for model downloads"
fi

# --------- STEP 9: Download HunyuanVideo I2V Models ----------
log "â¬‡ï¸ Downloading HunyuanVideo Image-to-Video models..."
MODEL_DIR="ckpts"
mkdir -p "$MODEL_DIR"

# Download HunyuanVideo I2V model (this is the large download)
log "ðŸ“¥ Downloading HunyuanVideo-I2V model (this may take 30-60 minutes)..."
log "ðŸ’¾ Expected download size: ~50-100GB"

if huggingface-cli download tencent/HunyuanVideo-I2V \
    --local-dir "$MODEL_DIR/HunyuanVideo-I2V" \
    --repo-type model; then
    success "âœ… HunyuanVideo-I2V model downloaded successfully"
else
    error "âŒ Failed to download HunyuanVideo-I2V model"
fi

# Verify critical I2V model files
I2V_ESSENTIAL_FILES=(
    "HunyuanVideo-I2V/hunyuan-video-i2v-720p/transformers/mp_rank_00_model_states.pt"
    "HunyuanVideo-I2V/hunyuan-video-i2v-720p/vae/pytorch_model.pt"
    "HunyuanVideo-I2V/text_encoder/pytorch_model.bin"
    "HunyuanVideo-I2V/text_encoder_2/pytorch_model.bin"
)

log "âœ… Validating I2V model files..."
for file in "${I2V_ESSENTIAL_FILES[@]}"; do
    full_path="$MODEL_DIR/$file"
    if [ -f "$full_path" ]; then
        file_size=$(du -h "$full_path" | cut -f1)
        success "âœ… $(basename "$file"): $file_size"
    else
        warn "âš ï¸  Missing: $file"
    fi
done

# --------- STEP 10: Create RTX 5090 I2V Configuration ----------
log "âš™ï¸ Creating RTX 5090 optimized I2V configuration..."
cat > rtx5090_i2v_config.py << 'EOF'
"""
RTX 5090 Optimized Configuration for HunyuanVideo Image-to-Video
"""
import torch
import os

class RTX5090_I2V_Config:
    def __init__(self):
        # RTX 5090 Blackwell architecture optimizations
        torch.backends.cuda.matmul.allow_tf32 = True
        torch.backends.cudnn.allow_tf32 = True
        torch.backends.cudnn.benchmark = True
        
        # Memory management for RTX 5090's 32GB VRAM
        if torch.cuda.is_available():
            torch.cuda.set_per_process_memory_fraction(0.95)
        
        # Device settings
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.dtype = torch.bfloat16  # RTX 5090 excels at bfloat16
        
        # I2V specific settings optimized for RTX 5090
        self.batch_size = 1  # Conservative for stability
        self.num_inference_steps = 30
        self.guidance_scale = 6.0
        self.image_guidance_scale = 1.8  # I2V specific
        
        # Video generation settings
        self.resolution = (1280, 720)
        self.num_frames = 129  # Optimal for RTX 5090's VRAM
        self.fps = 24
        self.video_length = 5.0  # seconds
        
        # Attention settings - CRITICAL for RTX 5090
        self.enable_flash_attention = True
        self.enable_memory_efficient_attention = True
        self.use_sage_attention = False  # AVOID - causes crashes
        self.attention_mode = "flash_attn"
        
        # Model paths
        self.model_base = "ckpts/HunyuanVideo-I2V"
        self.transformer_path = f"{self.model_base}/hunyuan-video-i2v-720p/transformers"
        self.vae_path = f"{self.model_base}/hunyuan-video-i2v-720p/vae"
        self.text_encoder_path = f"{self.model_base}/text_encoder"
        self.text_encoder_2_path = f"{self.model_base}/text_encoder_2"
        
        # Input image settings
        self.input_image_size = (1280, 720)
        self.image_format = "RGB"
        self.supported_formats = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']
        
        # Output settings
        self.output_format = "mp4"
        self.video_codec = "libx264"
        self.video_quality = "high"  # RTX 5090 can handle high quality
        self.pixel_format = "yuv420p"
        
    def apply_optimizations(self):
        """Apply RTX 5090 specific optimizations"""
        if torch.cuda.is_available():
            # Clear cache
            torch.cuda.empty_cache()
            
            # Enable SDPA optimizations for RTX 5090
            if hasattr(torch.backends.cuda, 'enable_flash_sdp'):
                torch.backends.cuda.enable_flash_sdp(True)
                torch.backends.cuda.enable_math_sdp(False)
                torch.backends.cuda.enable_mem_efficient_sdp(True)
            
            # Compiler optimizations
            torch.set_float32_matmul_precision('high')
            
            print("âœ… RTX 5090 Blackwell optimizations applied for I2V")
        else:
            print("âŒ CUDA not available")
    
    def get_model_info(self):
        """Get model information"""
        info = {
            "device": self.device,
            "dtype": str(self.dtype),
            "resolution": f"{self.resolution[0]}x{self.resolution[1]}",
            "frames": self.num_frames,
            "fps": self.fps,
            "video_length": f"{self.video_length}s",
            "batch_size": self.batch_size,
            "attention_mode": self.attention_mode
        }
        return info

# Global configuration instance
rtx5090_i2v_config = RTX5090_I2V_Config()
rtx5090_i2v_config.apply_optimizations()

# Print configuration
print("ðŸ”§ RTX 5090 I2V Configuration:")
for key, value in rtx5090_i2v_config.get_model_info().items():
    print(f"   {key}: {value}")
EOF

# --------- STEP 11: Create I2V Generation Script ----------
log "ðŸ“ Creating HunyuanVideo I2V generation script..."
cat > generate_i2v.py << 'EOF'
#!/usr/bin/env python3
"""
HunyuanVideo Image-to-Video Generation Script
Optimized for RTX 5090 on vast.ai
"""
import os
import sys
import torch
import argparse
import subprocess
from pathlib import Path
from PIL import Image
import time

# Import configuration
sys.path.append('.')
from rtx5090_i2v_config import rtx5090_i2v_config

def validate_input_image(image_path):
    """Validate and preprocess input image"""
    if not os.path.exists(image_path):
        print(f"âŒ Input image not found: {image_path}")
        return False
    
    try:
        # Open and validate image
        with Image.open(image_path) as img:
            print(f"ðŸ“¸ Input image: {img.size[0]}x{img.size[1]} ({img.mode})")
            
            # Check if image needs resizing
            target_size = rtx5090_i2v_config.input_image_size
            if img.size != target_size:
                print(f"ðŸ”„ Resizing image to {target_size[0]}x{target_size[1]}")
                img_resized = img.resize(target_size, Image.Resampling.LANCZOS)
                
                # Save resized image
                resized_path = image_path.replace('.', '_resized.')
                img_resized.save(resized_path)
                return resized_path
            
            return image_path
            
    except Exception as e:
        print(f"âŒ Error processing image: {e}")
        return False

def find_inference_script():
    """Find the I2V inference script"""
    possible_scripts = [
        "scripts/sample_image2video.py",
        "sample_i2v.py",
        "inference_i2v.py",
        "image2video.py",
        "hyvideo/inference_i2v.py"
    ]
    
    for script in possible_scripts:
        if os.path.exists(script):
            return script
    
    return None

def generate_i2v(image_path, prompt, output_dir):
    """Generate video from image using HunyuanVideo I2V"""
    
    # Validate input image
    processed_image = validate_input_image(image_path)
    if not processed_image:
        return False
    
    # Create output directory
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    # Find inference script
    inference_script = find_inference_script()
    if not inference_script:
        print("âŒ No I2V inference script found!")
        print("Available files:")
        for file in os.listdir('.'):
            if file.endswith('.py') and ('inference' in file or 'sample' in file):
                print(f"  - {file}")
        return False
    
    # Check model files
    model_base = rtx5090_i2v_config.model_base
    transformer_path = f"{model_base}/hunyuan-video-i2v-720p/transformers/mp_rank_00_model_states.pt"
    
    if not os.path.exists(transformer_path):
        print(f"âŒ Model not found: {transformer_path}")
        return False
    
    print(f"ðŸŽ¬ Generating I2V with RTX 5090 optimizations")
    print(f"ðŸ“¸ Input image: {processed_image}")
    print(f"ðŸ“ Prompt: {prompt}")
    print(f"ðŸ“ Resolution: {rtx5090_i2v_config.resolution[0]}x{rtx5090_i2v_config.resolution[1]}")
    print(f"ðŸŽžï¸ Frames: {rtx5090_i2v_config.num_frames}")
    print(f"ðŸ“ Output: {output_dir}")
    print(f"ðŸ”§ Using script: {inference_script}")
    
    # Build command
    cmd = [
        "python3", inference_script,
        "--model-path", transformer_path,
        "--input-image", processed_image,
        "--prompt", prompt,
        "--resolution", f"{rtx5090_i2v_config.resolution[0]}x{rtx5090_i2v_config.resolution[1]}",
        "--num-frames", str(rtx5090_i2v_config.num_frames),
        "--output", str(output_path),
        "--device", "cuda"
    ]
    
    # Add RTX 5090 optimizations if supported
    try:
        help_result = subprocess.run([
            "python3", inference_script, "--help"
        ], capture_output=True, text=True, timeout=30)
        
        help_text = help_result.stdout.lower()
        
        if "--dtype" in help_text:
            cmd.extend(["--dtype", "bfloat16"])
        if "--guidance-scale" in help_text:
            cmd.extend(["--guidance-scale", str(rtx5090_i2v_config.guidance_scale)])
        if "--image-guidance-scale" in help_text:
            cmd.extend(["--image-guidance-scale", str(rtx5090_i2v_config.image_guidance_scale)])
        if "--num-inference-steps" in help_text:
            cmd.extend(["--num-inference-steps", str(rtx5090_i2v_config.num_inference_steps)])
        if "--batch-size" in help_text:
            cmd.extend(["--batch-size", str(rtx5090_i2v_config.batch_size)])
        if "--enable-flash-attention" in help_text:
            cmd.append("--enable-flash-attention")
            
    except:
        print("âš ï¸  Could not check script parameters, using basic command")
    
    print(f"ðŸš€ Running: {' '.join(cmd)}")
    
    try:
        # Record start time
        start_time = time.time()
        
        # Run I2V generation
        result = subprocess.run(cmd, timeout=2400)  # 40 minute timeout
        
        if result.returncode == 0:
            elapsed_time = time.time() - start_time
            print(f"âœ… I2V generation completed in {elapsed_time/60:.1f} minutes!")
            
            # Convert to video
            convert_to_video(output_path)
            return True
        else:
            print(f"âŒ I2V generation failed with return code: {result.returncode}")
            return False
            
    except subprocess.TimeoutExpired:
        print("â° I2V generation timed out (40 minutes)")
        return False
    except Exception as e:
        print(f"âŒ Error: {e}")
        return False

def convert_to_video(output_dir):
    """Convert generated frames to MP4 video"""
    output_dir = Path(output_dir)
    
    # Look for frame files
    frame_patterns = ["*.png", "*.jpg", "*.jpeg"]
    frames = []
    for pattern in frame_patterns:
        frames.extend(list(output_dir.glob(pattern)))
    
    if not frames:
        print("âš ï¸  No frames found to convert")
        return False
    
    print(f"ðŸŽžï¸ Converting {len(frames)} frames to MP4...")
    
    # Determine frame pattern
    first_frame = sorted(frames)[0]
    if first_frame.name.endswith('.png'):
        frame_pattern = f"{output_dir}/%04d.png"
    else:
        frame_pattern = f"{output_dir}/%04d.jpg"
    
    output_video = output_dir / "i2v_output.mp4"
    
    # RTX 5090 optimized FFmpeg command
    ffmpeg_cmd = [
        "ffmpeg", "-y",
        "-framerate", str(rtx5090_i2v_config.fps),
        "-i", frame_pattern,
        "-c:v", rtx5090_i2v_config.video_codec,
        "-pix_fmt", rtx5090_i2v_config.pixel_format,
        "-crf", "18",  # High quality for RTX 5090
        "-preset", "slow",  # Better compression
        str(output_video)
    ]
    
    try:
        result = subprocess.run(ffmpeg_cmd, capture_output=True, text=True)
        if result.returncode == 0:
            print(f"ðŸŽ‰ Video saved: {output_video}")
            
            # Get video info
            file_size = output_video.stat().st_size / (1024*1024)  # MB
            print(f"ðŸ“Š Video size: {file_size:.1f} MB")
            return True
        else:
            print(f"âŒ FFmpeg failed: {result.stderr}")
            return False
    except Exception as e:
        print(f"âŒ Error converting video: {e}")
        return False

def main():
    parser = argparse.ArgumentParser(description='HunyuanVideo I2V Generation (RTX 5090 optimized)')
    parser.add_argument('--image', type=str, required=True, help='Input image path')
    parser.add_argument('--prompt', type=str, required=True, help='Text prompt for video generation')
    parser.add_argument('--output', type=str, default=None, help='Output directory')
    
    args = parser.parse_args()
    
    # Create output directory with timestamp
    if args.output is None:
        timestamp = int(time.time())
        args.output = f"outputs/i2v_{timestamp}"
    
    print("ðŸŽ¬ HunyuanVideo Image-to-Video Generation")
    print("=" * 50)
    
    success = generate_i2v(args.image, args.prompt, args.output)
    
    if success:
        print(f"\nðŸŽ‰ Success! Check your video in: {args.output}")
    else:
        print("\nâŒ Generation failed!")
        sys.exit(1)

if __name__ == "__main__":
    main()
EOF

chmod +x generate_i2v.py

# --------- STEP 12: Create Test Script ----------
log "ðŸ§ª Creating RTX 5090 I2V test script..."
cat > test_i2v_setup.py << 'EOF'
#!/usr/bin/env python3
import torch
import os
import sys
from pathlib import Path

def test_i2v_setup():
    """Test RTX 5090 I2V setup"""
    print("ðŸ” Testing HunyuanVideo I2V Setup on RTX 5090")
    print("=" * 60)
    
    # Test CUDA
    if not torch.cuda.is_available():
        print("âŒ CUDA not available")
        return False
    
    # GPU info
    gpu_name = torch.cuda.get_device_name(0)
    print(f"ðŸŽ® GPU: {gpu_name}")
    
    is_rtx5090 = "5090" in gpu_name
    if is_rtx5090:
        print("âœ… RTX 5090 detected")
    
    # Memory info
    total_memory = torch.cuda.get_device_properties(0).total_memory / 1e9
    print(f"ðŸ’¾ VRAM: {total_memory:.1f} GB")
    
    # Test bfloat16
    try:
        x = torch.randn(1000, 1000, device='cuda', dtype=torch.bfloat16)
        y = torch.randn(1000, 1000, device='cuda', dtype=torch.bfloat16)
        z = torch.matmul(x, y)
        torch.cuda.synchronize()
        print("âœ… bfloat16 operations working")
    except Exception as e:
        print(f"âŒ bfloat16 test failed: {e}")
        return False
    
    # Test configuration
    try:
        from rtx5090_i2v_config import rtx5090_i2v_config
        print("âœ… RTX 5090 I2V config loaded")
        print(f"   Resolution: {rtx5090_i2v_config.resolution[0]}x{rtx5090_i2v_config.resolution[1]}")
        print(f"   Frames: {rtx5090_i2v_config.num_frames}")
        print(f"   FPS: {rtx5090_i2v_config.fps}")
    except Exception as e:
        print(f"âŒ Config test failed: {e}")
        return False
    
    # Check model files
    model_files = [
        "ckpts/HunyuanVideo-I2V/hunyuan-video-i2v-720p/transformers/mp_rank_00_model_states.pt",
        "ckpts/HunyuanVideo-I2V/hunyuan-video-i2v-720p/vae/pytorch_model.pt",
        "ckpts/HunyuanVideo-I2V/text_encoder/pytorch_model.bin"
    ]
    
    print("\nðŸ“¦ Checking model files:")
    for model_file in model_files:
        if os.path.exists(model_file):
            size = os.path.getsize(model_file) / (1024**3)  # GB
            print(f"âœ… {os.path.basename(model_file)}: {size:.1f} GB")
        else:
            print(f"âŒ Missing: {model_file}")
            return False
    
    print("\nðŸŽ‰ RTX 5090 I2V setup test PASSED!")
    return True

if __name__ == "__main__":
    success = test_i2v_setup()
    sys.exit(0 if success else 1)
EOF

chmod +x test_i2v_setup.py

# --------- STEP 13: Create Sample Images ----------
log "ðŸ“¸ Creating sample input images..."
SAMPLES_DIR="sample_images"
mkdir -p "$SAMPLES_DIR"

# Create a simple sample image if none exist
python3 << 'EOF'
from PIL import Image, ImageDraw, ImageFont
import os

def create_sample_image():
    # Create a sample landscape image
    img = Image.new('RGB', (1280, 720), color='skyblue')
    draw = ImageDraw.Draw(img)
    
    # Draw simple landscape
    # Ground
    draw.rectangle([0, 500, 1280, 720], fill='green')
    
    # Mountains
    points = [(0, 500), (200, 300), (400, 400), (600, 250), (800, 350), (1000, 200), (1280, 300), (1280, 500)]
    draw.polygon(points, fill='gray')
    
    # Sun
    draw.ellipse([1000, 50, 1150, 200], fill='yellow')
    
    # Add text
    try:
        font = ImageFont.load_default()
        draw.text((50, 50), "Sample Landscape for HunyuanVideo I2V", fill='black', font=font)
    except:
        draw.text((50, 50), "Sample Landscape", fill='black')
    
    # Save
    img.save('sample_images/sample_landscape.jpg', quality=95)
    print("âœ… Created sample_landscape.jpg")

if not os.path.exists('sample_images/sample_landscape.jpg'):
    create_sample_image()
EOF

# --------- STEP 14: Create Activation Script ----------
log "ðŸ“œ Creating activation script..."
cat > activate_i2v.sh << 'EOF'
#!/bin/bash
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
cd "$SCRIPT_DIR"
source hunyuan_i2v_env/bin/activate

echo "ðŸŽ¬ HunyuanVideo I2V Environment Activated!"
echo "ðŸ“ Current directory: $(pwd)"
echo ""
echo "ðŸš€ Quick Commands:"
echo "  Test setup:   python test_i2v_setup.py"
echo "  Generate I2V: python generate_i2v.py --image sample_images/sample_landscape.jpg --prompt 'camera slowly zooming out'"
echo "  List samples: ls -la sample_images/"
echo ""

# Load optimizations
python -c "from rtx5090_i2v_config import rtx5090_i2v_config; print('âœ… RTX 5090 I2V optimizations loaded')" 2>/dev/null || echo "âš ï¸  Config not found"
EOF

chmod +x activate_i2v.sh

# --------- STEP 15: Create Documentation ----------
log "ðŸ“ Creating documentation..."
cat > README_I2V.md << 'EOF'
# HunyuanVideo Image-to-Video on RTX 5090

## ðŸš€ Quick Start

### 1. Activate Environment
```bash
source activate_i2v.sh
```

### 2. Test Setup
```bash
python test_i2v_setup.py
```

### 3. Generate Your First I2V
```bash
python generate_i2v.py \
  --image sample_images/sample_landscape.jpg \
  --prompt "camera slowly zooming out revealing a vast mountain landscape"
```

## ðŸŽ¬ RTX 5090 Optimized Settings
- **Resolution**: 1280x720 (optimal for RTX 5090)
- **Frames**: 129 (5.4 seconds at 24fps)
- **VRAM Usage**: ~22-28GB (perfect for 32GB RTX 5090)
- **Generation Time**: ~15-25 minutes
- **Quality**: Professional-grade with bfloat16 precision

## ðŸ“ Prompt Tips
- "camera slowly panning across the scene"
- "gentle wind blowing through the landscape" 
- "dramatic clouds moving across the sky"
- "cinematic lighting changes from day to sunset"

## ðŸ› Troubleshooting
- **CUDA errors**: Run `python test_i2v_setup.py`
- **Memory issues**: Reduce frames in `rtx5090_i2v_config.py`
- **Generation fails**: Check model files in `ckpts/HunyuanVideo-I2V/`
EOF

# --------- STEP 16: Run Final Tests ----------
log "ðŸ§ª Running final RTX 5090 setup tests..."

# Test PyTorch and CUDA
python -c "
import torch
print('ðŸ” Final RTX 5090 Test:')
print(f'âœ… PyTorch: {torch.__version__}')
print(f'âœ… CUDA: {torch.cuda.is_available()}')
if torch.cuda.is_available():
    print(f'âœ… GPU: {torch.cuda.get_device_name(0)}')
    print(f'âœ… VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB')
print('ðŸŽ¯ Ready for HunyuanVideo I2V generation!')
"

# Test configuration import
python -c "
try:
    from rtx5090_i2v_config import rtx5090_i2v_config
    print('âœ… RTX 5090 I2V configuration loaded successfully')
except Exception as e:
    print(f'âŒ Configuration error: {e}')
"

# --------- STEP 17: Final Instructions ----------
success "âœ… HunyuanVideo Image-to-Video RTX 5090 setup completed!"

echo ""
echo -e "${BLUE}============================================================${NC}"
echo -e "${GREEN}ðŸŽ‰ HunyuanVideo I2V Ready on RTX 5090!${NC}"
echo -e "${BLUE}============================================================${NC}"
echo ""
echo -e "${YELLOW}ðŸ“‹ Quick Commands:${NC}"
echo -e "1. ${GREEN}source activate_i2v.sh${NC}                           # Activate environment"
echo -e "2. ${GREEN}python test_i2v_setup.py${NC}                         # Test RTX 5090 setup"
echo -e "3. ${GREEN}python generate_i2v.py --image sample_images/sample_landscape.jpg --prompt \"cinematic camera movement\"${NC}"
echo ""
echo -e "${YELLOW}ðŸ“ Important Directories:${NC}"
echo -e "   Models: ${GREEN}ckpts/HunyuanVideo-I2V/${NC}"
echo -e "   Samples: ${GREEN}sample_images/${NC}"
echo -e "   Outputs: ${GREEN}outputs/${NC}"
echo ""
echo -e "${YELLOW}ðŸš€ RTX 5090 Optimizations Active:${NC}"
echo -e "   â€¢ Ubuntu $(lsb_release -rs) compatibility fixes"
echo -e "   â€¢ CUDA 12.8 PyTorch for Blackwell architecture"
echo -e "   â€¢ bfloat16 precision optimization"
echo -e "   â€¢ Flash attention enabled"
echo -e "   â€¢ 32GB VRAM management"
echo -e "   â€¢ 129 frames @ 1280x720 (optimal settings)"
echo ""
echo -e "${YELLOW}ðŸ“š Documentation:${NC}"
echo -e "   See ${GREEN}README_I2V.md${NC} for complete guide"
echo ""
echo -e "${GREEN}ðŸŽ¬ Ready to generate amazing Image-to-Video content!${NC}"
echo -e "${BLUE}============================================================${NC}"
